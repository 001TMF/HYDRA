---
phase: 03-sandbox-experiment-infrastructure
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - src/hydra/sandbox/journal.py
  - tests/test_journal.py
autonomous: true
requirements: [SBOX-03, SBOX-06]

must_haves:
  truths:
    - "Every experiment is logged with hypothesis, config diff, results, promotion decision, and tags"
    - "Journal is queryable by tag, date range, mutation type, and outcome (promotion_decision)"
    - "Config diff and results are stored as JSON for extensibility (Phase 4 escape hatch)"
    - "Queries with multiple filters combine with AND logic"
    - "Journal uses SQLite with WAL mode, consistent with existing FeatureStore pattern"
  artifacts:
    - path: "src/hydra/sandbox/journal.py"
      provides: "ExperimentJournal with SQLite storage and query layer"
      exports: ["ExperimentJournal", "ExperimentRecord"]
    - path: "tests/test_journal.py"
      provides: "Tests for logging, querying by all filter types, combined filters, edge cases"
  key_links:
    - from: "src/hydra/sandbox/journal.py"
      to: "sqlite3"
      via: "SQLite connection with WAL mode and indexed columns"
      pattern: "PRAGMA journal_mode=WAL"
    - from: "src/hydra/sandbox/journal.py"
      to: "src/hydra/sandbox/registry.py"
      via: "run_id and model_version fields linking to MLflow"
      pattern: "run_id"
---

<objective>
Create the experiment journal that logs every experiment with hypothesis, config diff, results, and promotion decision, and supports querying by tag, date range, mutation type, and outcome.

Purpose: SBOX-03 and SBOX-06 together require a structured, queryable experiment history. The Phase 4 agent loop will read journal history to avoid repeating failed experiments and to understand what mutations have been tried. SQLite provides the same pattern as FeatureStore (familiar, no new dependency).

Output: `src/hydra/sandbox/journal.py` with ExperimentJournal, ExperimentRecord, and full test suite.
</objective>

<execution_context>
@/Users/tristanfarmer/.claude/get-shit-done/workflows/execute-plan.md
@/Users/tristanfarmer/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-sandbox-experiment-infrastructure/03-RESEARCH.md
@src/hydra/data/store/feature_store.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ExperimentJournal with SQLite storage and query layer</name>
  <files>src/hydra/sandbox/journal.py</files>
  <action>
Create `src/hydra/sandbox/journal.py` with:

1. **ExperimentRecord dataclass** (from dataclasses):
   Fields:
   - `id: int | None = None` (auto-assigned by DB)
   - `created_at: str` (ISO 8601 UTC)
   - `hypothesis: str` (what we're testing)
   - `mutation_type: str` (e.g., "hyperparameter", "feature_add", "feature_remove", "architecture")
   - `config_diff: dict` (what changed from champion config -- stored as JSON)
   - `results: dict` (all metrics from evaluation -- stored as JSON)
   - `champion_metrics: dict | None = None` (champion metrics at time of experiment -- JSON)
   - `promotion_decision: str` (one of: "promoted", "rejected", "pending")
   - `promotion_reason: str | None = None` (why promoted/rejected)
   - `run_id: str | None = None` (MLflow run ID for cross-reference)
   - `model_version: int | None = None` (MLflow model version)
   - `tags: list[str] = field(default_factory=list)` (queryable tags -- stored as JSON array)
   - `metadata: dict = field(default_factory=dict)` (extensible escape hatch for Phase 4 -- stored as JSON)

2. **ExperimentJournal class**:
   - `__init__(self, db_path: str | Path)`:
     - Connect to SQLite at `db_path`.
     - `PRAGMA journal_mode=WAL` (matches FeatureStore pattern).
     - Call `_create_tables()`.

   - `_create_tables(self)`:
     Create the `experiments` table with the schema from research:
     ```sql
     CREATE TABLE IF NOT EXISTS experiments (
         id INTEGER PRIMARY KEY AUTOINCREMENT,
         created_at TEXT NOT NULL,
         hypothesis TEXT NOT NULL,
         mutation_type TEXT NOT NULL,
         config_diff TEXT NOT NULL,
         results TEXT NOT NULL,
         champion_metrics TEXT,
         promotion_decision TEXT NOT NULL,
         promotion_reason TEXT,
         run_id TEXT,
         model_version INTEGER,
         tags TEXT DEFAULT '[]',
         metadata TEXT DEFAULT '{}'
     );
     CREATE INDEX IF NOT EXISTS idx_experiments_created ON experiments(created_at);
     CREATE INDEX IF NOT EXISTS idx_experiments_mutation ON experiments(mutation_type);
     CREATE INDEX IF NOT EXISTS idx_experiments_decision ON experiments(promotion_decision);
     ```

   - `log_experiment(self, record: ExperimentRecord) -> int`:
     - INSERT record into experiments table.
     - Serialize `config_diff`, `results`, `champion_metrics`, `tags`, `metadata` as JSON strings via `json.dumps()`.
     - Return the auto-generated `id` (from cursor.lastrowid).

   - `get_experiment(self, experiment_id: int) -> ExperimentRecord | None`:
     - SELECT by id, deserialize JSON fields, return ExperimentRecord or None.

   - `query(self, tags: list[str] | None = None, date_from: str | None = None, date_to: str | None = None, mutation_type: str | None = None, outcome: str | None = None, limit: int = 100) -> list[ExperimentRecord]`:
     - Build WHERE clause dynamically with AND-combined filters.
     - `tags`: For each tag in the list, add `json_extract` or LIKE-based check on the tags JSON column. Use `tags LIKE '%"tag_value"%'` for simplicity (JSON array contains string).
     - `date_from`: `created_at >= ?`
     - `date_to`: `created_at <= ?`
     - `mutation_type`: `mutation_type = ?`
     - `outcome`: `promotion_decision = ?`
     - ORDER BY `created_at DESC`, LIMIT to `limit`.
     - Deserialize JSON fields in each row back to dicts/lists.
     - Return list of ExperimentRecord.

   - `count(self) -> int`: Return total experiment count.

   - `_row_to_record(self, row: tuple) -> ExperimentRecord`: Helper to deserialize a DB row into ExperimentRecord.

   - `close(self) -> None`: Close the database connection.

Use `import json` for serialization (stdlib, no dependency). Use `import sqlite3` (stdlib). Use `structlog` for logging.
  </action>
  <verify>
`python -c "from hydra.sandbox.journal import ExperimentJournal, ExperimentRecord; print('OK')"` succeeds.
  </verify>
  <done>ExperimentJournal with SQLite WAL mode, ExperimentRecord dataclass, log_experiment, get_experiment, query with all filter types, JSON serialization for extensible fields.</done>
</task>

<task type="auto">
  <name>Task 2: Test experiment journal logging and querying</name>
  <files>tests/test_journal.py</files>
  <action>
Create `tests/test_journal.py` with:

1. **Fixture**: `journal(tmp_path)` that creates an ExperimentJournal at `tmp_path / "journal.db"`.

2. **Helper**: `make_record(**overrides)` factory that returns ExperimentRecord with sensible defaults (hypothesis="Test hypothesis", mutation_type="hyperparameter", config_diff={"lr": 0.05}, results={"sharpe": 0.8}, promotion_decision="rejected", tags=["test"], created_at=datetime.utcnow().isoformat()).

3. **test_log_and_retrieve**: Log a record, get it by id. Assert all fields match including deserialized JSON fields.

4. **test_query_by_mutation_type**: Log 3 records: 2 with mutation_type="hyperparameter", 1 with "feature_add". Query by mutation_type="hyperparameter". Assert 2 results.

5. **test_query_by_outcome**: Log 3 records: 1 promoted, 2 rejected. Query by outcome="promoted". Assert 1 result.

6. **test_query_by_date_range**: Log 3 records with different created_at timestamps (2024-01-01, 2024-06-15, 2024-12-31). Query date_from="2024-06-01" date_to="2024-07-01". Assert 1 result (the June record).

7. **test_query_by_tag**: Log 2 records: one with tags=["drift", "urgent"], one with tags=["routine"]. Query tags=["drift"]. Assert 1 result.

8. **test_query_combined_filters**: Log records with varied fields. Query with mutation_type + outcome combined. Assert correct AND behavior.

9. **test_count**: Log 5 records. Assert count() returns 5.

10. **test_metadata_escape_hatch**: Log a record with metadata={"autonomy_level": "supervised", "parent_id": 42}. Retrieve it, assert metadata dict preserved.
  </action>
  <verify>`python -m pytest tests/test_journal.py -v` -- all tests pass.</verify>
  <done>10 tests covering logging, retrieval, all 4 query filter types (tag, date range, mutation type, outcome), combined filters, count, and metadata extensibility. All pass.</done>
</task>

</tasks>

<verification>
```bash
python -m pytest tests/test_journal.py -v
python -c "from hydra.sandbox.journal import ExperimentJournal, ExperimentRecord; print('OK')"
```
All tests pass. Journal stores experiments with JSON flexibility and supports all required query patterns.
</verification>

<success_criteria>
1. ExperimentRecord captures hypothesis, config_diff, results, promotion_decision, tags, metadata
2. Journal uses SQLite with WAL mode (matches FeatureStore pattern)
3. Query supports tag, date_from, date_to, mutation_type, outcome filters with AND logic
4. JSON columns (config_diff, results, tags, metadata) round-trip correctly
5. Metadata escape hatch field exists for Phase 4 extensibility
6. All 10 tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/03-sandbox-experiment-infrastructure/03-03-SUMMARY.md`
</output>
