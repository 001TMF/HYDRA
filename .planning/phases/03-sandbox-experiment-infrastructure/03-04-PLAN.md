---
phase: 03-sandbox-experiment-infrastructure
plan: 04
type: execute
wave: 1
depends_on: []
files_modified:
  - src/hydra/sandbox/drift/__init__.py
  - src/hydra/sandbox/drift/psi.py
  - src/hydra/sandbox/drift/ks.py
  - src/hydra/sandbox/drift/cusum.py
  - src/hydra/sandbox/drift/adwin.py
  - src/hydra/sandbox/observer.py
  - tests/test_drift.py
  - tests/test_observer.py
  - pyproject.toml
autonomous: true
requirements: [SBOX-04]

must_haves:
  truths:
    - "PSI computation detects significant distribution shift (PSI >= 0.25) with epsilon smoothing to handle zero bins"
    - "KS test detects distribution drift via two-sample test with configurable alpha"
    - "CUSUM detector signals change points in streaming metrics when cumulative deviation exceeds threshold"
    - "ADWIN detector identifies concept drift in streaming data using River's adaptive windowing"
    - "Observer combines performance drift (rolling Sharpe, drawdown, hit rate, calibration) with feature distribution drift (PSI, KS) and streaming drift (ADWIN, CUSUM) into a unified report"
  artifacts:
    - path: "src/hydra/sandbox/drift/psi.py"
      provides: "PSI computation with quantile-based binning and epsilon smoothing"
      exports: ["compute_psi"]
    - path: "src/hydra/sandbox/drift/ks.py"
      provides: "KS test wrapper"
      exports: ["check_ks_drift"]
    - path: "src/hydra/sandbox/drift/cusum.py"
      provides: "CUSUM change-point detector"
      exports: ["CUSUMDetector"]
    - path: "src/hydra/sandbox/drift/adwin.py"
      provides: "ADWIN wrapper around River"
      exports: ["ADWINDetector"]
    - path: "src/hydra/sandbox/observer.py"
      provides: "DriftObserver combining all drift detectors with performance monitoring"
      exports: ["DriftObserver", "DriftReport", "PerformanceDriftReport", "FeatureDriftReport"]
    - path: "tests/test_drift.py"
      provides: "Unit tests for all 4 drift detectors"
    - path: "tests/test_observer.py"
      provides: "Integration tests for DriftObserver"
  key_links:
    - from: "src/hydra/sandbox/drift/adwin.py"
      to: "river.drift.ADWIN"
      via: "River library ADWIN wrapper"
      pattern: "from river\\.drift import ADWIN"
    - from: "src/hydra/sandbox/drift/ks.py"
      to: "scipy.stats"
      via: "ks_2samp for two-sample KS test"
      pattern: "ks_2samp"
    - from: "src/hydra/sandbox/observer.py"
      to: "src/hydra/sandbox/drift/"
      via: "Imports all 4 drift detectors"
      pattern: "from hydra\\.sandbox\\.drift"
---

<objective>
Create the drift detection toolkit (PSI, KS, CUSUM, ADWIN) and the DriftObserver that combines performance and feature distribution monitoring into a unified drift report.

Purpose: SBOX-04 requires the observer to detect both performance degradation (rolling Sharpe, drawdown, hit rate, calibration) and feature distribution drift (PSI, KS) plus streaming change detection (ADWIN, CUSUM). This is the early warning system that triggers diagnostic cycles in Phase 4.

Output: `src/hydra/sandbox/drift/` with 4 detectors, `src/hydra/sandbox/observer.py` with DriftObserver, and comprehensive test suites.
</objective>

<execution_context>
@/Users/tristanfarmer/.claude/get-shit-done/workflows/execute-plan.md
@/Users/tristanfarmer/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-sandbox-experiment-infrastructure/03-RESEARCH.md
@src/hydra/model/evaluation.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create 4 drift detectors in drift subpackage</name>
  <files>src/hydra/sandbox/drift/__init__.py, src/hydra/sandbox/drift/psi.py, src/hydra/sandbox/drift/ks.py, src/hydra/sandbox/drift/cusum.py, src/hydra/sandbox/drift/adwin.py, pyproject.toml</files>
  <action>
Add `"river>=0.21"` to `dependencies` in `pyproject.toml` (if not already added by another plan during execution, check first). Run `uv sync`.

Create `src/hydra/sandbox/drift/__init__.py` exporting all 4 detectors.

**psi.py** -- `compute_psi(baseline: np.ndarray, current: np.ndarray, n_bins: int = 10, epsilon: float = 1e-4) -> float`:
- Quantile-based bin edges from baseline (`np.quantile` with `np.linspace(0, 1, n_bins + 1)`).
- Set `bin_edges[0] = -np.inf`, `bin_edges[-1] = np.inf`.
- Histogram both distributions against same bin edges.
- Add epsilon smoothing to proportions, then re-normalize.
- PSI = sum((current_pct - baseline_pct) * ln(current_pct / baseline_pct)).
- Return float. Interpretation: < 0.10 no shift, 0.10-0.25 moderate, >= 0.25 significant.
- Handle edge case: if baseline or current has fewer than n_bins unique values, reduce n_bins to `min(n_bins, n_unique - 1, max 2)`.

**ks.py** -- `check_ks_drift(baseline: np.ndarray, current: np.ndarray, alpha: float = 0.05) -> tuple[bool, float, float]`:
- Call `scipy.stats.ks_2samp(baseline, current)`.
- Return `(pvalue < alpha, statistic, pvalue)`.
- Handle edge case: if either array length < 2, return `(False, 0.0, 1.0)`.

**cusum.py** -- `CUSUMDetector` class:
- `__init__(self, target: float = 0.0, threshold: float = 5.0, drift: float = 0.5)`.
- `s_pos`, `s_neg` floats initialized to 0.
- `update(self, x: float) -> bool`: Standard CUSUM update formula per research. Returns True if drift detected.
- `reset(self) -> None`: Reset accumulators to 0.
- `@property drift_detected -> bool`.
- `@property cumulative_sum -> tuple[float, float]`: Returns (s_pos, s_neg).

**adwin.py** -- `ADWINDetector` class:
- `__init__(self, delta: float = 0.002, grace_period: int = 30)`.
- `self.detector = ADWIN(delta=delta, grace_period=grace_period)` from `river.drift`.
- `update(self, value: float) -> bool`: Feed observation, return `self.detector.drift_detected`.
- `@property estimation -> float`: Current mean estimate.
- `@property n_detections -> int`.
- `reset(self) -> None`: Create fresh ADWIN instance with same params.
  </action>
  <verify>
`python -c "from hydra.sandbox.drift import compute_psi, check_ks_drift, CUSUMDetector, ADWINDetector; print('OK')"` succeeds.
  </verify>
  <done>4 drift detectors created: PSI with epsilon smoothing, KS wrapper, CUSUM with standard algorithm, ADWIN wrapping River. All importable from hydra.sandbox.drift.</done>
</task>

<task type="auto">
  <name>Task 2: Create DriftObserver and test all components</name>
  <files>src/hydra/sandbox/observer.py, tests/test_drift.py, tests/test_observer.py</files>
  <action>
**observer.py**:

1. **PerformanceDriftReport dataclass**:
   - `sharpe_ratio: float` (rolling)
   - `max_drawdown: float` (rolling)
   - `hit_rate: float` (rolling)
   - `calibration: float` (Brier score of recent predictions vs actuals)
   - `sharpe_degraded: bool` (rolling Sharpe < baseline Sharpe * 0.5)
   - `drawdown_alert: bool` (drawdown worse than threshold, default -0.15)
   - `hit_rate_degraded: bool` (hit rate < 0.45)

2. **FeatureDriftReport dataclass**:
   - `psi_scores: dict[str, float]` (feature_name -> PSI)
   - `ks_results: dict[str, tuple[bool, float, float]]` (feature_name -> (drifted, stat, pval))
   - `drifted_features: list[str]` (features where PSI >= threshold OR KS rejected)

3. **DriftReport dataclass** (combined):
   - `performance: PerformanceDriftReport`
   - `feature: FeatureDriftReport | None`
   - `streaming_alerts: dict[str, bool]` (metric_name -> drift_detected from ADWIN/CUSUM)
   - `needs_diagnosis: bool` (True if any significant drift detected)
   - `timestamp: str` (ISO 8601)

4. **DriftObserver class**:
   - `__init__(self, config: dict | None = None)`:
     - Config keys: `psi_threshold` (0.25), `ks_alpha` (0.05), `adwin_delta` (0.002), `cusum_threshold` (5.0), `cusum_drift` (0.5), `sharpe_degradation_factor` (0.5), `drawdown_threshold` (-0.15), `hit_rate_floor` (0.45), `grace_period` (30).
     - Create ADWIN and CUSUM detectors for each monitored streaming metric (sharpe, drawdown, hit_rate).

   - `check_performance_drift(self, recent_returns: np.ndarray, predictions: np.ndarray, actuals: np.ndarray, probabilities: np.ndarray, baseline_sharpe: float) -> PerformanceDriftReport`:
     - Compute rolling Sharpe from `recent_returns` (same formula as evaluation.py `_compute_sharpe`).
     - Compute rolling max drawdown.
     - Compute hit rate from predictions vs actuals.
     - Compute Brier score: `mean((probabilities - actuals)**2)` for calibration (lower is better).
     - Compare against thresholds.

   - `check_feature_drift(self, baseline_features: np.ndarray, current_features: np.ndarray, feature_names: list[str]) -> FeatureDriftReport`:
     - For each feature column, compute PSI and KS test.
     - Collect drifted features (PSI >= threshold OR KS rejected).

   - `update_streaming(self, metric_name: str, value: float) -> bool`:
     - Feed value to ADWIN and CUSUM detectors for the named metric.
     - Return True if either detects drift.
     - If `metric_name` not in detectors, create new ADWIN+CUSUM pair.

   - `get_full_report(self, recent_returns: np.ndarray, predictions: np.ndarray, actuals: np.ndarray, probabilities: np.ndarray, baseline_sharpe: float, baseline_features: np.ndarray | None = None, current_features: np.ndarray | None = None, feature_names: list[str] | None = None) -> DriftReport`:
     - Call check_performance_drift + optionally check_feature_drift.
     - Collect streaming alerts.
     - Set `needs_diagnosis = True` if any of: sharpe_degraded, drawdown_alert, hit_rate_degraded, any drifted_features, any streaming_alerts.

   - `reset_streaming(self) -> None`: Reset all ADWIN and CUSUM detectors.

**tests/test_drift.py** (unit tests for 4 detectors):

1. **test_psi_identical_distributions**: Same data twice. Assert PSI < 0.01.
2. **test_psi_shifted_distribution**: Normal(0,1) vs Normal(2,1). Assert PSI > 0.25.
3. **test_psi_epsilon_no_nan**: Distribution with some zero bins. Assert PSI is finite (no NaN/Inf).
4. **test_ks_same_distribution**: Assert not drifted, p-value > 0.05.
5. **test_ks_different_distribution**: Normal(0,1) vs Normal(3,1). Assert drifted.
6. **test_cusum_stable_signal**: Feed 100 values near 0. Assert no drift.
7. **test_cusum_mean_shift**: Feed 50 values at 0 then 50 at 10. Assert drift detected.
8. **test_cusum_reset**: Detect drift, reset, assert s_pos and s_neg are 0.
9. **test_adwin_stable**: Feed 200 values from same distribution. Assert n_detections == 0.
10. **test_adwin_concept_drift**: Feed 100 from Normal(0,1) then 100 from Normal(5,1). Assert drift_detected at some point.

**tests/test_observer.py** (integration tests):

1. **test_performance_drift_healthy**: Returns from good model. Assert no degradation flags.
2. **test_performance_drift_degraded**: Returns that produce bad Sharpe. Assert sharpe_degraded=True.
3. **test_feature_drift_detected**: Baseline from Normal(0,1), current from Normal(5,1). Assert drifted_features is non-empty.
4. **test_full_report_needs_diagnosis**: Combine degraded performance + feature drift. Assert needs_diagnosis=True.
5. **test_streaming_drift_detection**: Feed stable values then shifted values. Assert update_streaming returns True after shift.

All tests use `np.random.seed(42)` for reproducibility.
  </action>
  <verify>
```bash
python -m pytest tests/test_drift.py tests/test_observer.py -v
```
All tests pass.
  </verify>
  <done>DriftObserver combines PSI, KS, CUSUM, ADWIN into unified drift monitoring. 10 unit tests for detectors, 5 integration tests for observer. All pass.</done>
</task>

</tasks>

<verification>
```bash
python -m pytest tests/test_drift.py tests/test_observer.py -v
python -c "from hydra.sandbox.observer import DriftObserver, DriftReport; print('OK')"
python -c "from hydra.sandbox.drift import compute_psi, check_ks_drift, CUSUMDetector, ADWINDetector; print('OK')"
```
All tests pass. Observer produces unified drift reports from 4 detection methods.
</verification>

<success_criteria>
1. PSI handles zero bins with epsilon smoothing (no NaN/Inf)
2. KS test wraps scipy.stats.ks_2samp with clear bool/stat/pval return
3. CUSUM detects mean shifts in streaming metrics
4. ADWIN uses River library for adaptive windowing
5. DriftObserver combines performance + feature + streaming drift into DriftReport
6. needs_diagnosis flag triggers when any drift exceeds thresholds
7. All 15 tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/03-sandbox-experiment-infrastructure/03-04-SUMMARY.md`
</output>
