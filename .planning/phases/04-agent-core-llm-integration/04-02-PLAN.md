---
phase: 04-agent-core-llm-integration
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/hydra/agent/autonomy.py
  - src/hydra/agent/rollback.py
  - src/hydra/agent/promotion.py
  - src/hydra/agent/dedup.py
  - src/hydra/agent/budget.py
  - tests/test_agent_guardrails.py
autonomous: true
requirements: [AGNT-06, AGNT-07, AGNT-08, AGNT-09, AGNT-17]

must_haves:
  truths:
    - "Autonomy levels (lockdown, supervised, semi-auto, autonomous) gate agent actions via permission matrix"
    - "Rollback triggers after sustained degradation over N consecutive periods (not a single bad period)"
    - "Rollback does not re-trigger until recovery is sustained for M consecutive healthy periods (hysteresis)"
    - "Candidate promotion requires beating champion on composite fitness across 3 of 5 independent evaluation windows"
    - "Semantically similar hypotheses (cosine similarity > 0.85) are rejected by deduplication"
    - "Per-head mutation budgets are tracked and heads with higher success rates get larger budgets"
    - "Cooldown timers prevent the same mutation type from being retried within a configurable window"
  artifacts:
    - path: "src/hydra/agent/autonomy.py"
      provides: "Autonomy levels and permission gating"
      exports: ["AutonomyLevel", "check_permission", "PERMISSIONS"]
    - path: "src/hydra/agent/rollback.py"
      provides: "Hysteresis-based rollback trigger"
      exports: ["HysteresisRollbackTrigger", "RollbackConfig"]
    - path: "src/hydra/agent/promotion.py"
      provides: "3-of-5 window promotion logic"
      exports: ["PromotionEvaluator", "PromotionResult"]
    - path: "src/hydra/agent/dedup.py"
      provides: "Semantic deduplication with cooldowns"
      exports: ["HypothesisDeduplicator"]
    - path: "src/hydra/agent/budget.py"
      provides: "Head reputation scoring and budget allocation"
      exports: ["HeadReputation", "BudgetManager"]
  key_links:
    - from: "src/hydra/agent/promotion.py"
      to: "src/hydra/sandbox/evaluator.py"
      via: "CompositeEvaluator.score() called on each evaluation window"
      pattern: "CompositeEvaluator|FitnessScore"
    - from: "src/hydra/agent/dedup.py"
      to: "sentence-transformers"
      via: "SentenceTransformer('all-MiniLM-L6-v2') for hypothesis embedding"
      pattern: "SentenceTransformer"
    - from: "src/hydra/agent/rollback.py"
      to: "src/hydra/sandbox/registry.py"
      via: "ModelRegistry.rollback() called when trigger fires"
      pattern: "ModelRegistry|rollback"
---

<objective>
Build the guardrail modules that protect the agent loop from bad behavior: autonomy gating, hysteresis rollback, 3-of-5 promotion, semantic deduplication, and reputation-based budgets.

Purpose: These modules are safety-critical. Without them, the agent loop could promote bad models, flap between candidates, run degenerate experiment loops, or take actions beyond its authorized level. They are independent of the LLM client and can be built in parallel.

Output: 5 guardrail modules in `src/hydra/agent/` with comprehensive test suite.
</objective>

<execution_context>
@/Users/tristanfarmer/.claude/get-shit-done/workflows/execute-plan.md
@/Users/tristanfarmer/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-agent-core-llm-integration/04-RESEARCH.md
@.planning/phases/03-sandbox-experiment-infrastructure/03-05-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create autonomy, rollback, and promotion modules</name>
  <files>
    src/hydra/agent/autonomy.py
    src/hydra/agent/rollback.py
    src/hydra/agent/promotion.py
  </files>
  <action>
    **Create `src/hydra/agent/autonomy.py`**: Follow research Pattern 5 exactly.
    - `AutonomyLevel(IntEnum)`: LOCKDOWN=0, SUPERVISED=1, SEMI_AUTO=2, AUTONOMOUS=3
    - `PERMISSIONS: dict[str, dict[AutonomyLevel, bool]]` mapping actions (observe, diagnose, hypothesize, experiment, promote, rollback) to permission per level. Follow the exact matrix from research:
      - observe: only LOCKDOWN=False
      - diagnose: only LOCKDOWN=False
      - hypothesize: only LOCKDOWN=False
      - experiment: LOCKDOWN=False, SUPERVISED=False, rest True
      - promote: only AUTONOMOUS=True
      - rollback: only LOCKDOWN=False
    - `check_permission(action: str, level: AutonomyLevel) -> bool`: Lookup in PERMISSIONS dict.
    - `requires_human_approval(action: str, level: AutonomyLevel) -> bool`: Returns True when action is allowed but at a level that requires human approval (e.g., promote at SUPERVISED or SEMI_AUTO).

    **Create `src/hydra/agent/rollback.py`**: Follow research Pattern 6 exactly.
    - `RollbackConfig` dataclass: degradation_threshold=0.15, sustained_periods=3, recovery_periods=5, cooldown_after_rollback=10
    - `HysteresisRollbackTrigger`:
      - `__init__(config: RollbackConfig | None = None)`: Stores config, _degraded_count=0, _healthy_count=0, _armed=True, _cooldown_remaining=0
      - `update(current_fitness: float, champion_fitness: float) -> bool`: Returns True if rollback should execute. Logic: if cooldown active, decrement and return False. Compute drop ratio. If degraded: increment _degraded_count, reset _healthy_count. If healthy: increment _healthy_count, reset _degraded_count. If armed and _degraded_count >= sustained_periods: trigger rollback, disarm, set cooldown. If not armed and _healthy_count >= recovery_periods: re-arm.
      - Properties: `is_armed`, `cooldown_remaining`, `degraded_count`

    **Create `src/hydra/agent/promotion.py`**:
    - `PromotionResult` dataclass: promoted (bool), windows_won (int), windows_total (int = 5), fitness_scores (list[float]), champion_scores (list[float])
    - `PromotionEvaluator`:
      - `__init__(windows_required: int = 3, total_windows: int = 5)`: Configurable threshold.
      - `evaluate(candidate_scores: list[float], champion_scores: list[float]) -> PromotionResult`: Compares candidate vs champion fitness on each window. Candidate wins a window if candidate_score > champion_score. Promoted if wins >= windows_required. Returns PromotionResult with full detail.
      - `evaluate_from_backtest_results(candidate_results: list, champion_results: list, evaluator: "CompositeEvaluator") -> PromotionResult`: Takes raw backtest results and evaluator, scores each, then delegates to evaluate(). Uses duck-typed attribute access (score_from_backtest) to avoid import coupling.
  </action>
  <verify>Run `python -c "from hydra.agent.autonomy import AutonomyLevel, check_permission; from hydra.agent.rollback import HysteresisRollbackTrigger; from hydra.agent.promotion import PromotionEvaluator; print('OK')"` succeeds.</verify>
  <done>Three guardrail modules importable with correct APIs. Autonomy permission matrix matches research spec. Rollback has hysteresis. Promotion requires 3-of-5 windows.</done>
</task>

<task type="auto">
  <name>Task 2: Create dedup, budget modules and comprehensive test suite</name>
  <files>
    src/hydra/agent/dedup.py
    src/hydra/agent/budget.py
    pyproject.toml
    tests/test_agent_guardrails.py
  </files>
  <action>
    **Add dependency** in pyproject.toml: add `sentence-transformers>=3.0` to project dependencies. Run `uv sync`.

    **Create `src/hydra/agent/dedup.py`**: Follow research semantic dedup code example.
    - `HypothesisDeduplicator`:
      - `__init__(similarity_threshold: float = 0.85, model_name: str = "all-MiniLM-L6-v2", cooldown_days: dict[str, int] | None = None)`: Loads SentenceTransformer model. `cooldown_days` maps mutation_type -> minimum days between retries (default: {"hyperparameter": 7, "feature_add": 14, "feature_remove": 14, "ensemble_method": 30}). Stores `_recent_embeddings: list[np.ndarray]`, `_recent_descriptions: list[str]`, `_recent_timestamps: list[datetime]`, `_recent_mutation_types: list[str]`.
      - `is_duplicate(description: str) -> bool`: Encode description, compute cosine similarity against all recent embeddings. Return True if max similarity > threshold.
      - `is_on_cooldown(mutation_type: str) -> bool`: Check if any recent entry with same mutation_type is within cooldown window.
      - `should_reject(description: str, mutation_type: str) -> tuple[bool, str]`: Combined check -- returns (rejected, reason) where reason is "duplicate" or "cooldown" or "".
      - `register(description: str, mutation_type: str) -> None`: Add embedding + metadata to memory.
      - `load_from_journal(journal: "ExperimentJournal", days: int = 30) -> None`: Query recent experiments from journal, register each.
      - `clear() -> None`: Reset all memory.

    **Create `src/hydra/agent/budget.py`**: Follow research HeadReputation code example.
    - `HeadReputation` dataclass:
      - name (str), total_proposals (int = 0), promoted_count (int = 0), rejected_count (int = 0), ema_success_rate (float = 0.5), ema_alpha (float = 0.3)
      - `success_rate` property: promoted_count / total_proposals (0.5 if no proposals yet -- neutral prior)
      - `record_outcome(promoted: bool)`: Update counters and EMA
      - `budget_multiplier() -> float`: max(0.25, min(2.0, ema_success_rate * 2.0))
    - `BudgetManager`:
      - `__init__(daily_budget: float = 20.0, base_experiments_per_head: int = 3)`: Configurable per user decision ($20/day dynamic cap).
      - `heads: dict[str, HeadReputation]`: Registry of head reputations.
      - `register_head(name: str) -> None`: Create HeadReputation entry.
      - `get_experiment_budget(head_name: str) -> int`: Returns base_experiments * budget_multiplier for that head (floored to int, minimum 1).
      - `record_outcome(head_name: str, promoted: bool) -> None`: Delegate to HeadReputation.record_outcome.
      - `get_report() -> dict[str, dict]`: Summary of all heads' success rates, multipliers, and budgets.

    **Create `tests/test_agent_guardrails.py`**: Comprehensive tests for all 5 modules.

    Autonomy tests:
    1. test_lockdown_blocks_all: All actions return False at LOCKDOWN
    2. test_supervised_allows_observe_blocks_experiment: SUPERVISED allows observe/diagnose/hypothesize/rollback, blocks experiment/promote
    3. test_autonomous_allows_all: All actions return True at AUTONOMOUS
    4. test_requires_human_approval_for_promote_at_semi_auto: promote at SEMI_AUTO requires human approval

    Rollback tests:
    5. test_no_rollback_on_single_bad_period: One degraded period does not trigger rollback
    6. test_rollback_after_sustained_degradation: 3 consecutive degraded periods triggers rollback
    7. test_no_retrigger_during_cooldown: After rollback, cooldown prevents re-trigger
    8. test_rearm_after_sustained_recovery: 5 healthy periods re-arms the trigger
    9. test_custom_config: Non-default RollbackConfig values are respected

    Promotion tests:
    10. test_promotion_3_of_5_wins: Candidate wins 3/5 windows -> promoted=True
    11. test_no_promotion_2_of_5: Candidate wins 2/5 -> promoted=False
    12. test_promotion_all_5: Candidate wins all 5 -> promoted=True, windows_won=5

    Dedup tests (use a smaller/faster model or mock SentenceTransformer for speed):
    13. test_identical_hypothesis_rejected: Same description registered then checked -> is_duplicate=True
    14. test_different_hypothesis_accepted: Very different description -> is_duplicate=False
    15. test_cooldown_blocks_same_mutation_type: Register hyperparameter mutation, check cooldown within window -> True
    16. test_cooldown_allows_after_window: Register with old timestamp -> cooldown expired -> False
    17. test_should_reject_combined: Tests the combined reject logic

    Budget tests:
    18. test_neutral_prior: New head has 0.5 success rate and 1.0 budget_multiplier
    19. test_successful_head_gets_more_budget: Head with 100% success -> multiplier approaches 2.0
    20. test_failing_head_gets_less_budget: Head with 0% success -> multiplier approaches 0.25
    21. test_budget_manager_experiment_allocation: BudgetManager returns experiments scaled by multiplier

    For dedup tests, to avoid downloading the full SentenceTransformer model in CI, mock `SentenceTransformer` to return deterministic numpy arrays. Use `np.array([1.0, 0.0, 0.0])` for one hypothesis and `np.array([0.99, 0.14, 0.0])` for a similar one (cosine similarity ~0.99) and `np.array([0.0, 1.0, 0.0])` for a different one (cosine similarity ~0.0).
  </action>
  <verify>Run `python -m pytest tests/test_agent_guardrails.py -v` -- all 21 tests pass.</verify>
  <done>All 5 guardrail modules tested with 21 tests. Autonomy gating, hysteresis rollback, 3-of-5 promotion, semantic dedup with cooldowns, and reputation-based budgets all verified. No real LLM or embedding calls needed.</done>
</task>

</tasks>

<verification>
1. All 5 modules importable from `hydra.agent`
2. Autonomy permission matrix matches research spec exactly
3. Rollback requires 3 sustained periods, has cooldown, re-arms after 5 healthy periods
4. Promotion requires 3-of-5 windows won
5. Dedup rejects similarity > 0.85 and enforces cooldown timers
6. Budget manager scales experiments by head success rate
7. All 21 tests pass
</verification>

<success_criteria>
Five guardrail modules fully operational with 21+ tests. Autonomy correctly gates all 6 action types at 4 levels. Rollback has working hysteresis. Promotion evaluates 5 independent windows. Dedup uses semantic embeddings with configurable threshold and mutation-type cooldowns. Budget manager tracks head reputations with EMA and scales experiment allocations.
</success_criteria>

<output>
After completion, create `.planning/phases/04-agent-core-llm-integration/04-02-SUMMARY.md`
</output>
