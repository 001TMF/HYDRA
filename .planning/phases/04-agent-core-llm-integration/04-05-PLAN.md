---
phase: 04-agent-core-llm-integration
plan: 05
type: execute
wave: 4
depends_on: [04-01, 04-03, 04-04]
files_modified:
  - src/hydra/agent/heads/__init__.py
  - src/hydra/agent/heads/technical.py
  - src/hydra/agent/heads/research.py
  - src/hydra/agent/heads/structural.py
  - src/hydra/agent/research/__init__.py
  - src/hydra/agent/research/congressional.py
  - src/hydra/agent/research/usda.py
  - src/hydra/agent/research/seasonal.py
  - src/hydra/agent/research/cycles.py
  - src/hydra/agent/research/fed.py
  - src/hydra/agent/research/proposals.py
  - tests/test_heads.py
  - tests/test_research_sources.py
autonomous: true
requirements: [AGNT-12, AGNT-13, AGNT-14, AGNT-16]

user_setup:
  - service: financial-modeling-prep
    why: "Senate STOCK Act trading data for Research Head congressional signal"
    env_vars:
      - name: FMP_API_KEY
        source: "https://site.financialmodelingprep.com/developer/docs -- create account, get API key (free tier available)"
  - service: usda-ers
    why: "WASDE crop reports for Research Head agricultural signals"
    env_vars:
      - name: USDA_API_KEY
        source: "https://www.ers.usda.gov/developer/data-apis/ -- register for API key"
  - service: fred
    why: "Federal Reserve Economic Data (FRED) for macro signals (yield curve, Fed funds rate, inflation)"
    env_vars:
      - name: FRED_API_KEY
        source: "https://fred.stlouisfed.org/docs/api/api_key.html -- create account, request API key (free)"

must_haves:
  truths:
    - "Technical Head wraps the hypothesis engine and generates hyperparameter/feature/architecture mutations"
    - "Research Head discovers new data signals from congressional trades, USDA data, FRED/Fed macro data, and seasonal patterns"
    - "Research Head proposals are validated through sandbox testing before integration (AGNT-16)"
    - "Structural Head proposes ensemble methods, alternative prediction targets, and feature interactions"
    - "All three heads implement the BaseHead interface and can be registered with the Coordinator"
    - "Data source integrations have graceful error handling and local caching"
    - "Research Head uses pre-configured APIs as primary, not web search (per research recommendation)"
    - "FRED fetcher provides yield curve signals, Fed funds rate, and macro snapshot for Research Head regime detection"
    - "Congressional module includes lobbying and committee hearing stubs with graceful degradation (returns empty list with TODO)"
  artifacts:
    - path: "src/hydra/agent/heads/technical.py"
      provides: "Technical Head: hyperparameter/feature/architecture mutations"
      exports: ["TechnicalHead"]
    - path: "src/hydra/agent/heads/research.py"
      provides: "Research Head: new signal discovery with full autonomy"
      exports: ["ResearchHead"]
    - path: "src/hydra/agent/heads/structural.py"
      provides: "Structural Head: ensemble/target/interaction proposals"
      exports: ["StructuralHead"]
    - path: "src/hydra/agent/research/fed.py"
      provides: "FRED API integration for Fed macro data (yield curve, funds rate, inflation)"
      exports: ["FREDFetcher", "FREDSeries"]
    - path: "src/hydra/agent/research/proposals.py"
      provides: "Proposal system for new signal sandbox validation"
      exports: ["ProposalSystem", "SignalProposal"]
  key_links:
    - from: "src/hydra/agent/heads/technical.py"
      to: "src/hydra/agent/hypothesis.py"
      via: "Wraps HypothesisEngine for mutation generation"
      pattern: "HypothesisEngine"
    - from: "src/hydra/agent/heads/research.py"
      to: "src/hydra/agent/research/"
      via: "Uses data source modules for signal discovery"
      pattern: "congressional|usda|seasonal|cycles|fed"
    - from: "src/hydra/agent/research/proposals.py"
      to: "src/hydra/sandbox/replay.py"
      via: "MarketReplayEngine for proposal sandbox validation"
      pattern: "MarketReplayEngine"
    - from: "src/hydra/agent/heads/structural.py"
      to: "src/hydra/agent/llm/schemas.py"
      via: "Generates Hypothesis objects with ensemble/target mutation types"
      pattern: "Hypothesis|MutationType"
---

<objective>
Build the three specialized heads (Technical, Research, Structural) and the Research Head's data source integrations plus proposal system.

Purpose: The multi-headed architecture is HYDRA's competitive moat. Each head attacks drift from a different angle: Technical tunes the existing model, Research discovers entirely new signals, and Structural changes the model architecture. The Research Head has full autonomy to discover, test, and integrate new signals without human approval (per locked user decision).

Output: Three head implementations, six data source modules (congressional with lobbying/hearings stubs, USDA, FRED, seasonal, cycles, proposals), and the proposal system. Test suites for heads and data sources.
</objective>

<execution_context>
@/Users/tristanfarmer/.claude/get-shit-done/workflows/execute-plan.md
@/Users/tristanfarmer/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-agent-core-llm-integration/04-RESEARCH.md
@.planning/phases/04-agent-core-llm-integration/04-01-SUMMARY.md
@.planning/phases/04-agent-core-llm-integration/04-03-SUMMARY.md
@.planning/phases/04-agent-core-llm-integration/04-04-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create three specialized heads implementing BaseHead</name>
  <files>
    src/hydra/agent/heads/technical.py
    src/hydra/agent/heads/research.py
    src/hydra/agent/heads/structural.py
    src/hydra/agent/heads/__init__.py
    tests/test_heads.py
  </files>
  <action>
    **Note:** All Phase 4 dependencies (`statsmodels>=0.14`, `wasdeparser>=1.0`, `fredapi>=0.5`, etc.) are installed by 04-01 (all Phase 4 deps consolidated there). Do NOT modify pyproject.toml in this plan.

    **Update `src/hydra/agent/heads/__init__.py`**: Export BaseHead, TechnicalHead, ResearchHead, StructuralHead.

    **Create `src/hydra/agent/heads/technical.py`**:
    - `TechnicalHead(BaseHead)`:
      - `__init__(self, hypothesis_engine: HypothesisEngine)`: Wraps existing AGNT-03 engine.
      - `name -> "technical"`, `head_type -> "technical"`
      - `generate_hypotheses(self, diagnosis: DiagnosisResult, journal: ExperimentJournal, max_hypotheses: int = 3) -> list[Hypothesis]`: Delegates to hypothesis_engine.generate(diagnosis, head_name="technical", max_hypotheses=max_hypotheses). This head is the simplest -- it wraps AGNT-03 with the BaseHead interface.

    **Create `src/hydra/agent/heads/structural.py`**:
    - `STRUCTURAL_PLAYBOOK: dict[str, list[dict]]`: Distinct playbook focused on structural mutations:
      - "performance_degradation": ensemble_method (bagging, boosting blend), prediction_target (change horizon from 1d to 3d)
      - "feature_distribution_drift": feature_engineering (rolling z-scores, rank transforms), prediction_target (relative returns vs absolute)
      - "regime_change": ensemble_method (regime-conditional ensemble), feature_engineering (regime indicator features)
      - "overfitting": ensemble_method (reduce complexity via pruning + averaging), feature_engineering (PCA dimensionality reduction)
      - "data_quality_issue": feature_engineering (robust scaling, outlier-resistant transforms)
    - `StructuralHead(BaseHead)`:
      - `__init__(self, llm_client: "LLMClient | None" = None)`: Optional LLM for augmentation.
      - `name -> "structural"`, `head_type -> "structural"`
      - `generate_hypotheses(self, diagnosis: DiagnosisResult, journal: ExperimentJournal, max_hypotheses: int = 3) -> list[Hypothesis]`:
        1. Get entries from STRUCTURAL_PLAYBOOK for diagnosis.primary_cause.value.
        2. Query journal for recent structural experiments (mutation_type in ["ensemble_method", "prediction_target", "feature_engineering"]) to avoid repetition.
        3. If LLM available: ask LLM to rank and customize entries based on diagnosis context.
        4. Fallback: return first max_hypotheses entries converted to Hypothesis objects with head_name="structural".

    **Create `src/hydra/agent/heads/research.py`**:
    - `ResearchHead(BaseHead)`:
      - `__init__(self, llm_client: "LLMClient | None" = None, proposal_system: "ProposalSystem | None" = None, data_sources: dict | None = None)`: LLM for signal discovery reasoning. proposal_system for sandbox validation. data_sources is a dict of data fetcher instances.
      - `name -> "research"`, `head_type -> "research"`
      - `generate_hypotheses(self, diagnosis: DiagnosisResult, journal: ExperimentJournal, max_hypotheses: int = 3) -> list[Hypothesis]`:
        1. Check for new available data from configured sources (congressional trades, USDA releases, seasonal events). This is lightweight -- just checks cached availability flags, does not make API calls on every cycle.
        2. If LLM available: Send diagnosis + available data summary to LLM with RESEARCH_PROMPT. Ask it to propose new signal integrations that address the diagnosed root cause. Parse response into list of Hypothesis with mutation_type=MutationType.NEW_DATA_SIGNAL.
        3. Fallback (no LLM): Use heuristic signal proposals based on data availability and diagnosis category. E.g., if regime_change detected and ENSO data is stale -> propose refreshing ENSO signal.
        4. Each hypothesis includes description of the new signal, expected impact, and config_diff specifying the new data source to integrate.
      - `_check_data_availability(self) -> dict[str, bool]`: Check which data sources have fresh data available (from local cache timestamps).

    Per locked user decision: Research Head has **full autonomy** -- can discover, test, and integrate signals without human approval. User gets notified after, not before.

    **Create `tests/test_heads.py`**:
    1. test_technical_head_delegates_to_engine: Mock HypothesisEngine. Verify TechnicalHead.generate_hypotheses() calls engine.generate() with correct args.
    2. test_technical_head_implements_base: Verify TechnicalHead is instance of BaseHead, has name="technical".
    3. test_structural_head_returns_hypotheses: StructuralHead with no LLM generates hypotheses from STRUCTURAL_PLAYBOOK for performance_degradation diagnosis.
    4. test_structural_head_all_categories_covered: STRUCTURAL_PLAYBOOK has entries for all 5 DriftCategory values.
    5. test_structural_head_implements_base: Verify is BaseHead, name="structural".
    6. test_research_head_implements_base: Verify is BaseHead, name="research".
    7. test_research_head_rule_based_generates: ResearchHead with no LLM generates at least 1 hypothesis for regime_change diagnosis.
    8. test_all_heads_return_valid_hypotheses: All 3 heads return list[Hypothesis] that pass Pydantic validation.
    9. test_heads_set_correct_head_name: Each head sets head_name field to its own name on generated hypotheses.
  </action>
  <verify>Run `python -m pytest tests/test_heads.py -v` -- all 9 tests pass.</verify>
  <done>Three heads implement BaseHead interface. Technical wraps HypothesisEngine. Structural has its own playbook for ensemble/target/interaction mutations. Research uses data sources with LLM augmentation. All 9 tests pass.</done>
</task>

<task type="auto">
  <name>Task 2: Create Research Head data sources and proposal system</name>
  <files>
    src/hydra/agent/research/__init__.py
    src/hydra/agent/research/congressional.py
    src/hydra/agent/research/usda.py
    src/hydra/agent/research/fed.py
    src/hydra/agent/research/seasonal.py
    src/hydra/agent/research/cycles.py
    src/hydra/agent/research/proposals.py
    tests/test_research_sources.py
  </files>
  <action>
    **Create `src/hydra/agent/research/__init__.py`**: Export all data source classes (CongressionalTradesFetcher, USDAFetcher, FREDFetcher, SeasonalFetcher, CycleDetector) and ProposalSystem.

    **Create `src/hydra/agent/research/congressional.py`**: Follow research code example.
    - `CongressionalTrade(BaseModel)`: senator, transaction_date (date), ticker, asset_description, transaction_type, amount_range, committees (list[str])
    - `LobbyingRecord(BaseModel)`: filing_date (date), registrant (str), client (str), issue_area (str), amount (float | None), specific_issues (list[str]). Stub model for future lobbying data integration.
    - `CommitteeHearing(BaseModel)`: hearing_date (date), committee (str), title (str), witnesses (list[str]), topics (list[str]). Stub model for future committee hearing data.
    - `CongressionalTradesFetcher`:
      - `__init__(self, api_key: str | None = None)`: FMP API key. If None, operates in degraded mode (returns empty).
      - `BASE_URL = "https://financialmodelingprep.com/api/v3"`
      - `get_recent_senate_trades(self, days: int = 30) -> list[CongressionalTrade]`: GET /senate-trading with api_key param. Parse response JSON into CongressionalTrade list. Cache results for 24 hours (store in _cache dict with timestamp). On httpx error: log warning, return cached data or empty list.
      - `get_agriculture_committee_trades(self) -> list[CongressionalTrade]`: Filter trades by Agriculture Committee members or ag-related tickers (ADM, BG, CTVA, DE, FMC, MOS, NTR, CF per research).
      - `get_lobbying_records(self, days: int = 90) -> list[LobbyingRecord]`: Stub method -- returns empty list with logged info message "Lobbying data source not yet configured (TODO: select API -- OpenSecrets or Senate LDA)". Graceful degradation per locked decision requiring lobbying signals.
      - `get_committee_hearings(self, days: int = 30) -> list[CommitteeHearing]`: Stub method -- returns empty list with logged info message "Committee hearing data source not yet configured (TODO: select API -- congress.gov or ProPublica)". Graceful degradation per locked decision requiring committee hearing signals.
      - Use httpx.Client with 30s timeout.

    **Create `src/hydra/agent/research/usda.py`**:
    - `WASDEReport(BaseModel)`: report_date (date), commodity (str), metric (str), value (float), unit (str), revision_from_previous (float | None)
    - `USDAFetcher`:
      - `__init__(self, api_key: str | None = None)`: USDA ERS API key. If None, degraded mode.
      - `get_latest_wasde(self, commodity: str = "corn") -> list[WASDEReport]`: Fetch latest WASDE data for commodity. Cache 24 hours. Try wasdeparser library first; if it fails, try direct USDA ERS API endpoint. Return structured report. On error: return cached or empty.
      - `get_crop_calendar(self) -> dict[str, dict]`: Return static embedded planting/harvest calendar for major commodities (corn, soybeans, wheat, cotton). Dates as month ranges. No API call needed.

    **Create `src/hydra/agent/research/fed.py`**: FRED API integration per locked decision requiring Fed data source.
    - `FREDSeries(BaseModel)`: series_id (str), observation_date (date), value (float | None), units (str)
    - `FREDFetcher`:
      - `__init__(self, api_key: str | None = None)`: FRED API key from fredapi. If None, uses `fredapi.Fred()` which supports the `FRED_API_KEY` env var automatically. If no key at all, operates in degraded mode (returns empty).
      - `DEFAULT_SERIES: dict[str, str]`: Map of commonly used series: {"fed_funds_rate": "FEDFUNDS", "yield_10y": "DGS10", "yield_2y": "DGS2", "yield_spread_10y2y": "T10Y2Y", "breakeven_5y": "T5YIE", "initial_claims": "ICSA", "cpi_yoy": "CPIAUCSL"}
      - `get_series(self, series_id: str, days: int = 365) -> list[FREDSeries]`: Fetch FRED series data using fredapi.Fred().get_series(). Cache results for 24 hours. On error: log warning, return cached data or empty list. Parse pandas Series into list[FREDSeries].
      - `get_yield_curve_signals(self) -> dict[str, float | None]`: Convenience method that fetches yield spread, Fed funds rate, and breakeven inflation in one call. Returns dict with latest values. Used by Research Head for macro regime detection.
      - `get_macro_snapshot(self) -> dict[str, float | None]`: Fetch latest values for all DEFAULT_SERIES. Returns dict mapping human-readable name to latest value.

    **Create `src/hydra/agent/research/seasonal.py`**:
    - `ENSOData(BaseModel)`: date (date), oni_value (float), phase (str -- "El Nino" | "La Nina" | "Neutral")
    - `SeasonalFetcher`:
      - `__init__(self)`: No API key needed for NOAA.
      - `get_enso_data(self) -> list[ENSOData]`: Download ONI data from NOAA CPC (direct CSV/text download, no API key). Cache for 7 days. Parse into ENSOData list. Classify phase based on ONI value (>0.5 = El Nino, <-0.5 = La Nina, else Neutral).
      - `get_planting_dates(self, commodity: str = "corn") -> dict`: Return static reference data for US planting/pollination/harvest windows.

    **Create `src/hydra/agent/research/cycles.py`**:
    - `CycleDecomposition(BaseModel)`: period_years (float), amplitude (float), phase_offset (float), significance (float)
    - `CycleDetector`:
      - `__init__(self)`: No external dependencies beyond statsmodels.
      - `detect_cycles(self, prices: np.ndarray, periods: list[int] | None = None) -> list[CycleDecomposition]`: Use statsmodels MSTL (Multi-Seasonal-Trend decomposition using LOESS) to decompose price series into trend + seasonal components for the specified periods (default: [252, 756, 1260, 2520] for ~1, 3, 5, 10 year cycles in trading days). Return amplitude and significance of each detected cycle.
      - `get_current_position(self, prices: np.ndarray, period_days: int) -> float`: Return where we are in the cycle (0-1, where 0 = trough, 0.5 = peak) for a given period.
    Per locked decision: Use BOTH historical decomposition AND external event calendars combined.

    **Create `src/hydra/agent/research/proposals.py`**:
    - `SignalProposal(BaseModel)`: signal_name (str), source_module (str), description (str), expected_features (list[str]), validation_status (str = "pending"), fitness_improvement (float | None = None)
    - `ProposalSystem`:
      - `__init__(self, journal: ExperimentJournal | None = None)`: Optional journal for logging proposals.
      - `proposals: list[SignalProposal]`
      - `submit_proposal(self, proposal: SignalProposal) -> None`: Add to proposals list.
      - `validate_proposal(self, proposal: SignalProposal, replay_engine: "MarketReplayEngine | None" = None) -> SignalProposal`: Run sandbox validation. For now, this is a placeholder that marks proposal as "validated" if the source module can be imported and data can be fetched. Full replay-based validation will be wired in the integration phase. Update proposal.validation_status to "validated" or "failed".
      - `get_validated_proposals(self) -> list[SignalProposal]`: Return proposals with status="validated".
      - `integrate_proposal(self, proposal: SignalProposal) -> bool`: Mark a validated proposal for integration. Log to journal if available. Returns True on success. Per user decision: full autonomy -- no human approval needed.

    **Create `tests/test_research_sources.py`**:
    1. test_congressional_degraded_mode: CongressionalTradesFetcher(api_key=None) returns empty list gracefully.
    2. test_congressional_cache_hit: Mock httpx.Client.get to return sample data. Call twice. Verify second call uses cache (httpx not called again).
    3. test_ag_committee_filter: Provide sample trades, verify agriculture filter selects correct tickers.
    4. test_lobbying_stub_returns_empty: CongressionalTradesFetcher().get_lobbying_records() returns empty list without error.
    5. test_hearings_stub_returns_empty: CongressionalTradesFetcher().get_committee_hearings() returns empty list without error.
    6. test_usda_degraded_mode: USDAFetcher(api_key=None) returns empty.
    7. test_crop_calendar_static_data: get_crop_calendar() returns dict with corn, soybeans, wheat.
    8. test_fred_degraded_mode: FREDFetcher with no API key returns empty list gracefully.
    9. test_fred_default_series_defined: FREDFetcher.DEFAULT_SERIES contains fed_funds_rate, yield_10y, yield_2y, yield_spread_10y2y keys.
    10. test_fred_yield_curve_signals: Mock fredapi.Fred to return sample data. Verify get_yield_curve_signals() returns dict with expected keys.
    11. test_enso_phase_classification: ONI > 0.5 -> El Nino, < -0.5 -> La Nina.
    12. test_cycle_detector_synthetic: Generate synthetic sine wave at known period. Verify detect_cycles finds approximate period.
    13. test_proposal_lifecycle: Submit -> validate -> get_validated -> integrate. Verify status transitions.
    14. test_proposal_invalid_source_fails: Proposal with nonexistent source_module fails validation.
  </action>
  <verify>Run `python -m pytest tests/test_research_sources.py -v` -- all 14 tests pass.</verify>
  <done>Six data source modules (congressional with lobbying/hearings stubs, USDA, FRED, seasonal, cycles) with graceful degradation and caching. Proposal system with full lifecycle. All 14 tests pass without requiring real API keys (mocked or degraded mode).</done>
</task>

</tasks>

<verification>
1. `python -c "from hydra.agent.heads import TechnicalHead, ResearchHead, StructuralHead; from hydra.agent.research import ProposalSystem, FREDFetcher"` succeeds
2. `python -m pytest tests/test_heads.py tests/test_research_sources.py -v` -- all 23 tests pass
3. All three heads implement BaseHead interface
4. Data sources return empty lists when API keys are missing (graceful degradation)
5. FRED fetcher provides yield curve and macro signals for Research Head
6. Congressional module has lobbying/hearings stub methods that return empty lists gracefully
7. Proposal system tracks lifecycle from submission through validation to integration
</verification>

<success_criteria>
Three specialized heads operational: Technical wraps hypothesis engine, Structural has ensemble/target/interaction playbook, Research discovers new signals from 5 data source categories (congressional with lobbying/hearings stubs, USDA, FRED/Fed, seasonal, cycles). Data sources gracefully degrade without API keys. FRED fetcher provides yield curve and macro snapshot per locked decision requiring Fed data. Congressional module includes lobbying and committee hearing stubs per locked decision. Proposal system validates new signals through sandbox testing before integration. Research Head has full autonomy per user decision. All 23 tests pass.
</success_criteria>

<output>
After completion, create `.planning/phases/04-agent-core-llm-integration/04-05-SUMMARY.md`
</output>
