---
phase: 04-agent-core-llm-integration
plan: 05
type: execute
wave: 3
depends_on: [04-01, 04-03]
files_modified:
  - src/hydra/agent/heads/technical.py
  - src/hydra/agent/heads/research.py
  - src/hydra/agent/heads/structural.py
  - src/hydra/agent/research/__init__.py
  - src/hydra/agent/research/congressional.py
  - src/hydra/agent/research/usda.py
  - src/hydra/agent/research/seasonal.py
  - src/hydra/agent/research/cycles.py
  - src/hydra/agent/research/proposals.py
  - tests/test_heads.py
  - tests/test_research_sources.py
autonomous: true
requirements: [AGNT-12, AGNT-13, AGNT-14, AGNT-16]

user_setup:
  - service: financial-modeling-prep
    why: "Senate STOCK Act trading data for Research Head congressional signal"
    env_vars:
      - name: FMP_API_KEY
        source: "https://site.financialmodelingprep.com/developer/docs -- create account, get API key (free tier available)"
  - service: usda-ers
    why: "WASDE crop reports for Research Head agricultural signals"
    env_vars:
      - name: USDA_API_KEY
        source: "https://www.ers.usda.gov/developer/data-apis/ -- register for API key"

must_haves:
  truths:
    - "Technical Head wraps the hypothesis engine and generates hyperparameter/feature/architecture mutations"
    - "Research Head discovers new data signals from congressional trades, USDA data, and seasonal patterns"
    - "Research Head proposals are validated through sandbox testing before integration (AGNT-16)"
    - "Structural Head proposes ensemble methods, alternative prediction targets, and feature interactions"
    - "All three heads implement the BaseHead interface and can be registered with the Coordinator"
    - "Data source integrations have graceful error handling and local caching"
    - "Research Head uses pre-configured APIs as primary, not web search (per research recommendation)"
  artifacts:
    - path: "src/hydra/agent/heads/technical.py"
      provides: "Technical Head: hyperparameter/feature/architecture mutations"
      exports: ["TechnicalHead"]
    - path: "src/hydra/agent/heads/research.py"
      provides: "Research Head: new signal discovery with full autonomy"
      exports: ["ResearchHead"]
    - path: "src/hydra/agent/heads/structural.py"
      provides: "Structural Head: ensemble/target/interaction proposals"
      exports: ["StructuralHead"]
    - path: "src/hydra/agent/research/proposals.py"
      provides: "Proposal system for new signal sandbox validation"
      exports: ["ProposalSystem", "SignalProposal"]
  key_links:
    - from: "src/hydra/agent/heads/technical.py"
      to: "src/hydra/agent/hypothesis.py"
      via: "Wraps HypothesisEngine for mutation generation"
      pattern: "HypothesisEngine"
    - from: "src/hydra/agent/heads/research.py"
      to: "src/hydra/agent/research/"
      via: "Uses data source modules for signal discovery"
      pattern: "congressional|usda|seasonal|cycles"
    - from: "src/hydra/agent/research/proposals.py"
      to: "src/hydra/sandbox/replay.py"
      via: "MarketReplayEngine for proposal sandbox validation"
      pattern: "MarketReplayEngine"
    - from: "src/hydra/agent/heads/structural.py"
      to: "src/hydra/agent/llm/schemas.py"
      via: "Generates Hypothesis objects with ensemble/target mutation types"
      pattern: "Hypothesis|MutationType"
---

<objective>
Build the three specialized heads (Technical, Research, Structural) and the Research Head's data source integrations plus proposal system.

Purpose: The multi-headed architecture is HYDRA's competitive moat. Each head attacks drift from a different angle: Technical tunes the existing model, Research discovers entirely new signals, and Structural changes the model architecture. The Research Head has full autonomy to discover, test, and integrate new signals without human approval (per locked user decision).

Output: Three head implementations, five data source modules, and the proposal system. Test suites for heads and data sources.
</objective>

<execution_context>
@/Users/tristanfarmer/.claude/get-shit-done/workflows/execute-plan.md
@/Users/tristanfarmer/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-agent-core-llm-integration/04-RESEARCH.md
@.planning/phases/04-agent-core-llm-integration/04-01-SUMMARY.md
@.planning/phases/04-agent-core-llm-integration/04-03-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create three specialized heads implementing BaseHead</name>
  <files>
    src/hydra/agent/heads/technical.py
    src/hydra/agent/heads/research.py
    src/hydra/agent/heads/structural.py
    src/hydra/agent/heads/__init__.py
    tests/test_heads.py
    pyproject.toml
  </files>
  <action>
    **Add dependencies** in pyproject.toml: add `statsmodels>=0.14` and `wasdeparser>=1.0` to project dependencies. Run `uv sync`.

    **Update `src/hydra/agent/heads/__init__.py`**: Export BaseHead, TechnicalHead, ResearchHead, StructuralHead.

    **Create `src/hydra/agent/heads/technical.py`**:
    - `TechnicalHead(BaseHead)`:
      - `__init__(self, hypothesis_engine: HypothesisEngine)`: Wraps existing AGNT-03 engine.
      - `name -> "technical"`, `head_type -> "technical"`
      - `generate_hypotheses(self, diagnosis: DiagnosisResult, journal: ExperimentJournal, max_hypotheses: int = 3) -> list[Hypothesis]`: Delegates to hypothesis_engine.generate(diagnosis, head_name="technical", max_hypotheses=max_hypotheses). This head is the simplest -- it wraps AGNT-03 with the BaseHead interface.

    **Create `src/hydra/agent/heads/structural.py`**:
    - `STRUCTURAL_PLAYBOOK: dict[str, list[dict]]`: Distinct playbook focused on structural mutations:
      - "performance_degradation": ensemble_method (bagging, boosting blend), prediction_target (change horizon from 1d to 3d)
      - "feature_distribution_drift": feature_engineering (rolling z-scores, rank transforms), prediction_target (relative returns vs absolute)
      - "regime_change": ensemble_method (regime-conditional ensemble), feature_engineering (regime indicator features)
      - "overfitting": ensemble_method (reduce complexity via pruning + averaging), feature_engineering (PCA dimensionality reduction)
      - "data_quality_issue": feature_engineering (robust scaling, outlier-resistant transforms)
    - `StructuralHead(BaseHead)`:
      - `__init__(self, llm_client: "LLMClient | None" = None)`: Optional LLM for augmentation.
      - `name -> "structural"`, `head_type -> "structural"`
      - `generate_hypotheses(self, diagnosis: DiagnosisResult, journal: ExperimentJournal, max_hypotheses: int = 3) -> list[Hypothesis]`:
        1. Get entries from STRUCTURAL_PLAYBOOK for diagnosis.primary_cause.value.
        2. Query journal for recent structural experiments (mutation_type in ["ensemble_method", "prediction_target", "feature_engineering"]) to avoid repetition.
        3. If LLM available: ask LLM to rank and customize entries based on diagnosis context.
        4. Fallback: return first max_hypotheses entries converted to Hypothesis objects with head_name="structural".

    **Create `src/hydra/agent/heads/research.py`**:
    - `ResearchHead(BaseHead)`:
      - `__init__(self, llm_client: "LLMClient | None" = None, proposal_system: "ProposalSystem | None" = None, data_sources: dict | None = None)`: LLM for signal discovery reasoning. proposal_system for sandbox validation. data_sources is a dict of data fetcher instances.
      - `name -> "research"`, `head_type -> "research"`
      - `generate_hypotheses(self, diagnosis: DiagnosisResult, journal: ExperimentJournal, max_hypotheses: int = 3) -> list[Hypothesis]`:
        1. Check for new available data from configured sources (congressional trades, USDA releases, seasonal events). This is lightweight -- just checks cached availability flags, does not make API calls on every cycle.
        2. If LLM available: Send diagnosis + available data summary to LLM with RESEARCH_PROMPT. Ask it to propose new signal integrations that address the diagnosed root cause. Parse response into list of Hypothesis with mutation_type=MutationType.NEW_DATA_SIGNAL.
        3. Fallback (no LLM): Use heuristic signal proposals based on data availability and diagnosis category. E.g., if regime_change detected and ENSO data is stale -> propose refreshing ENSO signal.
        4. Each hypothesis includes description of the new signal, expected impact, and config_diff specifying the new data source to integrate.
      - `_check_data_availability(self) -> dict[str, bool]`: Check which data sources have fresh data available (from local cache timestamps).

    Per locked user decision: Research Head has **full autonomy** -- can discover, test, and integrate signals without human approval. User gets notified after, not before.

    **Create `tests/test_heads.py`**:
    1. test_technical_head_delegates_to_engine: Mock HypothesisEngine. Verify TechnicalHead.generate_hypotheses() calls engine.generate() with correct args.
    2. test_technical_head_implements_base: Verify TechnicalHead is instance of BaseHead, has name="technical".
    3. test_structural_head_returns_hypotheses: StructuralHead with no LLM generates hypotheses from STRUCTURAL_PLAYBOOK for performance_degradation diagnosis.
    4. test_structural_head_all_categories_covered: STRUCTURAL_PLAYBOOK has entries for all 5 DriftCategory values.
    5. test_structural_head_implements_base: Verify is BaseHead, name="structural".
    6. test_research_head_implements_base: Verify is BaseHead, name="research".
    7. test_research_head_rule_based_generates: ResearchHead with no LLM generates at least 1 hypothesis for regime_change diagnosis.
    8. test_all_heads_return_valid_hypotheses: All 3 heads return list[Hypothesis] that pass Pydantic validation.
    9. test_heads_set_correct_head_name: Each head sets head_name field to its own name on generated hypotheses.
  </action>
  <verify>Run `python -m pytest tests/test_heads.py -v` -- all 9 tests pass.</verify>
  <done>Three heads implement BaseHead interface. Technical wraps HypothesisEngine. Structural has its own playbook for ensemble/target/interaction mutations. Research uses data sources with LLM augmentation. All 9 tests pass.</done>
</task>

<task type="auto">
  <name>Task 2: Create Research Head data sources and proposal system</name>
  <files>
    src/hydra/agent/research/__init__.py
    src/hydra/agent/research/congressional.py
    src/hydra/agent/research/usda.py
    src/hydra/agent/research/seasonal.py
    src/hydra/agent/research/cycles.py
    src/hydra/agent/research/proposals.py
    tests/test_research_sources.py
  </files>
  <action>
    **Create `src/hydra/agent/research/__init__.py`**: Export all data source classes and ProposalSystem.

    **Create `src/hydra/agent/research/congressional.py`**: Follow research code example.
    - `CongressionalTrade(BaseModel)`: senator, transaction_date (date), ticker, asset_description, transaction_type, amount_range, committees (list[str])
    - `CongressionalTradesFetcher`:
      - `__init__(self, api_key: str | None = None)`: FMP API key. If None, operates in degraded mode (returns empty).
      - `BASE_URL = "https://financialmodelingprep.com/api/v3"`
      - `get_recent_senate_trades(self, days: int = 30) -> list[CongressionalTrade]`: GET /senate-trading with api_key param. Parse response JSON into CongressionalTrade list. Cache results for 24 hours (store in _cache dict with timestamp). On httpx error: log warning, return cached data or empty list.
      - `get_agriculture_committee_trades(self) -> list[CongressionalTrade]`: Filter trades by Agriculture Committee members or ag-related tickers (ADM, BG, CTVA, DE, FMC, MOS, NTR, CF per research).
      - Use httpx.Client with 30s timeout.

    **Create `src/hydra/agent/research/usda.py`**:
    - `WASDEReport(BaseModel)`: report_date (date), commodity (str), metric (str), value (float), unit (str), revision_from_previous (float | None)
    - `USDAFetcher`:
      - `__init__(self, api_key: str | None = None)`: USDA ERS API key. If None, degraded mode.
      - `get_latest_wasde(self, commodity: str = "corn") -> list[WASDEReport]`: Fetch latest WASDE data for commodity. Cache 24 hours. Try wasdeparser library first; if it fails, try direct USDA ERS API endpoint. Return structured report. On error: return cached or empty.
      - `get_crop_calendar(self) -> dict[str, dict]`: Return static embedded planting/harvest calendar for major commodities (corn, soybeans, wheat, cotton). Dates as month ranges. No API call needed.

    **Create `src/hydra/agent/research/seasonal.py`**:
    - `ENSOData(BaseModel)`: date (date), oni_value (float), phase (str -- "El Nino" | "La Nina" | "Neutral")
    - `SeasonalFetcher`:
      - `__init__(self)`: No API key needed for NOAA.
      - `get_enso_data(self) -> list[ENSOData]`: Download ONI data from NOAA CPC (direct CSV/text download, no API key). Cache for 7 days. Parse into ENSOData list. Classify phase based on ONI value (>0.5 = El Nino, <-0.5 = La Nina, else Neutral).
      - `get_planting_dates(self, commodity: str = "corn") -> dict`: Return static reference data for US planting/pollination/harvest windows.

    **Create `src/hydra/agent/research/cycles.py`**:
    - `CycleDecomposition(BaseModel)`: period_years (float), amplitude (float), phase_offset (float), significance (float)
    - `CycleDetector`:
      - `__init__(self)`: No external dependencies beyond statsmodels.
      - `detect_cycles(self, prices: np.ndarray, periods: list[int] | None = None) -> list[CycleDecomposition]`: Use statsmodels MSTL (Multi-Seasonal-Trend decomposition using LOESS) to decompose price series into trend + seasonal components for the specified periods (default: [252, 756, 1260, 2520] for ~1, 3, 5, 10 year cycles in trading days). Return amplitude and significance of each detected cycle.
      - `get_current_position(self, prices: np.ndarray, period_days: int) -> float`: Return where we are in the cycle (0-1, where 0 = trough, 0.5 = peak) for a given period.
    Per locked decision: Use BOTH historical decomposition AND external event calendars combined.

    **Create `src/hydra/agent/research/proposals.py`**:
    - `SignalProposal(BaseModel)`: signal_name (str), source_module (str), description (str), expected_features (list[str]), validation_status (str = "pending"), fitness_improvement (float | None = None)
    - `ProposalSystem`:
      - `__init__(self, journal: ExperimentJournal | None = None)`: Optional journal for logging proposals.
      - `proposals: list[SignalProposal]`
      - `submit_proposal(self, proposal: SignalProposal) -> None`: Add to proposals list.
      - `validate_proposal(self, proposal: SignalProposal, replay_engine: "MarketReplayEngine | None" = None) -> SignalProposal`: Run sandbox validation. For now, this is a placeholder that marks proposal as "validated" if the source module can be imported and data can be fetched. Full replay-based validation will be wired in the integration phase. Update proposal.validation_status to "validated" or "failed".
      - `get_validated_proposals(self) -> list[SignalProposal]`: Return proposals with status="validated".
      - `integrate_proposal(self, proposal: SignalProposal) -> bool`: Mark a validated proposal for integration. Log to journal if available. Returns True on success. Per user decision: full autonomy -- no human approval needed.

    **Create `tests/test_research_sources.py`**:
    1. test_congressional_degraded_mode: CongressionalTradesFetcher(api_key=None) returns empty list gracefully.
    2. test_congressional_cache_hit: Mock httpx.Client.get to return sample data. Call twice. Verify second call uses cache (httpx not called again).
    3. test_ag_committee_filter: Provide sample trades, verify agriculture filter selects correct tickers.
    4. test_usda_degraded_mode: USDAFetcher(api_key=None) returns empty.
    5. test_crop_calendar_static_data: get_crop_calendar() returns dict with corn, soybeans, wheat.
    6. test_enso_phase_classification: ONI > 0.5 -> El Nino, < -0.5 -> La Nina.
    7. test_cycle_detector_synthetic: Generate synthetic sine wave at known period. Verify detect_cycles finds approximate period.
    8. test_proposal_lifecycle: Submit -> validate -> get_validated -> integrate. Verify status transitions.
    9. test_proposal_invalid_source_fails: Proposal with nonexistent source_module fails validation.
  </action>
  <verify>Run `python -m pytest tests/test_research_sources.py -v` -- all 9 tests pass.</verify>
  <done>Five data source modules with graceful degradation and caching. Proposal system with full lifecycle. All 9 tests pass without requiring real API keys (mocked or degraded mode).</done>
</task>

</tasks>

<verification>
1. `python -c "from hydra.agent.heads import TechnicalHead, ResearchHead, StructuralHead; from hydra.agent.research import ProposalSystem"` succeeds
2. `python -m pytest tests/test_heads.py tests/test_research_sources.py -v` -- all 18 tests pass
3. All three heads implement BaseHead interface
4. Data sources return empty lists when API keys are missing (graceful degradation)
5. Proposal system tracks lifecycle from submission through validation to integration
</verification>

<success_criteria>
Three specialized heads operational: Technical wraps hypothesis engine, Structural has ensemble/target/interaction playbook, Research discovers new signals from 4 data source categories (congressional, USDA, seasonal, cycles). Data sources gracefully degrade without API keys. Proposal system validates new signals through sandbox testing before integration. Research Head has full autonomy per user decision. All 18 tests pass.
</success_criteria>

<output>
After completion, create `.planning/phases/04-agent-core-llm-integration/04-05-SUMMARY.md`
</output>
