---
phase: 02-signal-layer-baseline-model
plan: 03
type: tdd
wave: 2
depends_on:
  - 02-01
files_modified:
  - src/hydra/signals/divergence/__init__.py
  - src/hydra/signals/divergence/detector.py
  - tests/test_divergence_detector.py
autonomous: true
requirements:
  - SGNL-02
  - SGNL-03

must_haves:
  truths:
    - "Divergence detector classifies into exactly 6 types per PRD taxonomy"
    - "Output includes direction (+1/-1/0), magnitude (z-scored), divergence_type (string), confidence ([0,1]), suggested_bias (string)"
    - "Classification is rule-based using thresholds, NOT ML"
    - "When options quality is DEGRADED, confidence is reduced and type defaults to neutral"
    - "Magnitude is z-scored against expanding-window historical divergences"
  artifacts:
    - path: "src/hydra/signals/divergence/detector.py"
      provides: "DivergenceSignal dataclass and classify_divergence function"
      exports: ["DivergenceSignal", "classify_divergence"]
    - path: "src/hydra/signals/divergence/__init__.py"
      provides: "Public re-exports for divergence module"
    - path: "tests/test_divergence_detector.py"
      provides: "TDD tests covering all 6 divergence types"
      min_lines: 80
  key_links:
    - from: "src/hydra/signals/divergence/detector.py"
      to: "src/hydra/signals/sentiment/cot_scoring.py"
      via: "uses SentimentScore.score as sentiment input"
      pattern: "sentiment_score"
    - from: "src/hydra/signals/divergence/detector.py"
      to: "src/hydra/signals/options_math/moments.py"
      via: "uses ImpliedMoments.mean, .skew, .kurtosis as options signal"
      pattern: "implied_mean|implied_skew|implied_kurtosis"
    - from: "src/hydra/signals/divergence/detector.py"
      to: "src/hydra/signals/options_math/density.py"
      via: "uses DataQuality enum for options quality assessment"
      pattern: "DataQuality"
---

<objective>
Build the divergence detector that classifies the relationship between options-implied signals and COT sentiment into the 6-type taxonomy from PRD Section 5.3, producing a DivergenceSignal with direction, magnitude, type, confidence, and suggested bias.

Purpose: This is the core signal generator. It compares what options math says (implied distribution) against what the crowd thinks (COT sentiment) and identifies exploitable mispricings. The LightGBM model (Plan 02-04) uses the numerical components of this signal as features.

Output: `src/hydra/signals/divergence/detector.py` with `DivergenceSignal` dataclass and `classify_divergence()` function, fully tested via TDD.
</objective>

<execution_context>
@/Users/tristanfarmer/.claude/get-shit-done/workflows/execute-plan.md
@/Users/tristanfarmer/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-signal-layer-baseline-model/02-RESEARCH.md
@.planning/phases/02-signal-layer-baseline-model/02-01-SUMMARY.md
@src/hydra/signals/options_math/moments.py
@src/hydra/signals/options_math/density.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: RED -- Write failing tests for all 6 divergence types</name>
  <files>tests/test_divergence_detector.py, src/hydra/signals/divergence/__init__.py</files>
  <action>
Create `src/hydra/signals/divergence/__init__.py` (empty for now).

Create `tests/test_divergence_detector.py` with test cases covering all 6 divergence types from PRD Section 5.3:

1. **test_options_bullish_sentiment_bearish**: implied_mean > spot (bullish options) + sentiment_score < -0.3 (bearish sentiment) -> type="options_bullish_sentiment_bearish", direction=+1, suggested_bias="long"

2. **test_options_bearish_sentiment_bullish**: implied_mean < spot (bearish options) + sentiment_score > 0.3 (bullish sentiment) -> type="options_bearish_sentiment_bullish", direction=-1, suggested_bias="short"

3. **test_sentiment_overreaction**: options near neutral (implied_mean ~= spot) + abs(sentiment_score) > 0.6 -> type="sentiment_overreaction", direction opposite of sentiment, suggested_bias="fade_sentiment"

4. **test_early_signal**: options directional + significant skew change + sentiment near zero -> type="early_signal", suggested_bias="early_entry"

5. **test_trend_follow**: both options and sentiment aligned in same direction -> type="trend_follow", suggested_bias="trend_follow"

6. **test_volatility_play**: high kurtosis (> 4.0) + flat mean (near spot) -> type="volatility_play", suggested_bias="vol_play"

Additional tests:
7. **test_degraded_quality_reduces_confidence**: DataQuality.DEGRADED -> confidence < 0.5
8. **test_magnitude_is_z_scored**: magnitude is normalized, not raw difference
9. **test_output_dataclass_fields**: DivergenceSignal has all 5 required fields
10. **test_neutral_when_no_clear_signal**: Neither side strong -> direction=0, type="neutral"

Import from `hydra.signals.divergence.detector import DivergenceSignal, classify_divergence`.
Import `DataQuality` from `hydra.signals.options_math.density`.

Function signature:
```python
classify_divergence(
    implied_mean: float | None,
    spot: float,
    implied_skew: float | None,
    implied_kurtosis: float | None,
    sentiment_score: float,
    sentiment_confidence: float,
    options_quality: DataQuality,
    history: list[float] | None = None,  # historical divergence values for z-scoring
) -> DivergenceSignal
```

Run tests -- all MUST fail (RED phase).
  </action>
  <verify>`cd /Users/tristanfarmer/Documents/HYDRA && python -m pytest tests/test_divergence_detector.py -v` shows ImportError or failures</verify>
  <done>Test file exists with 10+ test cases covering all 6 divergence types, all failing</done>
</task>

<task type="auto">
  <name>Task 2: GREEN + REFACTOR -- Implement divergence detector</name>
  <files>src/hydra/signals/divergence/detector.py, src/hydra/signals/divergence/__init__.py</files>
  <action>
Implement `src/hydra/signals/divergence/detector.py`:

```python
from dataclasses import dataclass
from hydra.signals.options_math.density import DataQuality

@dataclass
class DivergenceSignal:
    direction: int          # +1 long, -1 short, 0 neutral
    magnitude: float        # z-scored magnitude of divergence
    divergence_type: str    # one of 6 taxonomy types + "neutral"
    confidence: float       # [0, 1] composite confidence
    suggested_bias: str     # action recommendation
```

`classify_divergence()` implementation:

1. **Handle DEGRADED quality**: If options_quality != FULL or implied_mean is None, set confidence_penalty = 0.5 and use only what's available. If implied_mean is None, return neutral signal.

2. **Compute options bias**: `options_bias = (implied_mean - spot) / spot` -- positive = bullish, negative = bearish.

3. **Compute magnitude**: raw_divergence = options_bias - (sentiment_score / scale_factor). If history provided and len >= 10, z-score against history using scipy.stats.zscore. Otherwise use raw_divergence.

4. **Classification rules** (evaluated in priority order):
   - **volatility_play**: kurtosis is not None and kurtosis > 4.0 and abs(options_bias) < 0.02
   - **options_bullish_sentiment_bearish**: options_bias > 0.01 and sentiment_score < -0.3
   - **options_bearish_sentiment_bullish**: options_bias < -0.01 and sentiment_score > 0.3
   - **sentiment_overreaction**: abs(options_bias) < 0.02 and abs(sentiment_score) > 0.6
   - **early_signal**: abs(options_bias) > 0.01 and skew is not None and abs(implied_skew) > 0.5 and abs(sentiment_score) < 0.3
   - **trend_follow**: sign(options_bias) == sign(sentiment_score) and both abs > threshold
   - **neutral**: none of the above match

5. **Confidence**: Combine sentiment_confidence * options_quality_factor (1.0 for FULL, 0.5 for DEGRADED) * signal_strength (magnitude-based).

6. **Direction**: +1 if suggested bias is long/early_entry with positive options, -1 if short/fade with negative, 0 if neutral/vol_play.

Thresholds should be configurable defaults, not hardcoded magic numbers. Use module-level constants.

Update `__init__.py` to re-export: `from hydra.signals.divergence.detector import DivergenceSignal, classify_divergence`.

Run all tests -- they MUST pass (GREEN). Refactor for clarity.
  </action>
  <verify>`cd /Users/tristanfarmer/Documents/HYDRA && python -m pytest tests/test_divergence_detector.py -v` -- all tests pass</verify>
  <done>All 10+ tests pass. DivergenceSignal correctly classifies all 6 taxonomy types. Degraded quality reduces confidence. Magnitude is z-scored when history available.</done>
</task>

</tasks>

<verification>
```bash
cd /Users/tristanfarmer/Documents/HYDRA
python -m pytest tests/test_divergence_detector.py -v
python -c "from hydra.signals.divergence import DivergenceSignal, classify_divergence; print('Import OK')"
```
</verification>

<success_criteria>
- classify_divergence correctly identifies all 6 PRD taxonomy types with correct suggested_bias
- DivergenceSignal has all 5 fields: direction, magnitude, divergence_type, confidence, suggested_bias
- DEGRADED quality reduces confidence below 0.5
- Neutral returned when no clear signal
- Rule-based classification (no ML) with configurable thresholds
- All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/02-signal-layer-baseline-model/02-03-SUMMARY.md`
</output>
