---
phase: 02-signal-layer-baseline-model
plan: 04
type: execute
wave: 3
depends_on:
  - 02-01
  - 02-02
  - 02-03
files_modified:
  - src/hydra/model/__init__.py
  - src/hydra/model/features.py
  - src/hydra/model/baseline.py
  - tests/test_model_features.py
  - tests/test_baseline_model.py
autonomous: true
requirements:
  - MODL-01

must_haves:
  truths:
    - "Feature matrix assembly pulls divergence signal components + implied moments + Greeks flows + COT features from feature store via point-in-time correct queries"
    - "LightGBM binary classifier trained with conservative defaults (num_leaves=31, lr=0.1, n_estimators=100)"
    - "Model handles NaN features natively (LightGBM's built-in NaN handling) for DEGRADED quality data"
    - "Binary target: price up (+1) or down (0) over configurable N-day horizon (default 5 days)"
    - "Feature importance is extractable for diagnostics"
  artifacts:
    - path: "src/hydra/model/features.py"
      provides: "FeatureAssembler class that builds feature matrix from feature store + signals"
      exports: ["FeatureAssembler"]
    - path: "src/hydra/model/baseline.py"
      provides: "BaselineModel wrapping LightGBM with train/predict_proba/feature_importance"
      exports: ["BaselineModel"]
    - path: "tests/test_model_features.py"
      provides: "Tests for feature matrix assembly"
    - path: "tests/test_baseline_model.py"
      provides: "Tests for LightGBM wrapper"
  key_links:
    - from: "src/hydra/model/features.py"
      to: "src/hydra/data/store/feature_store.py"
      via: "get_features_at for point-in-time correct feature retrieval"
      pattern: "get_features_at"
    - from: "src/hydra/model/features.py"
      to: "src/hydra/signals/divergence/detector.py"
      via: "uses DivergenceSignal numerical components as features"
      pattern: "DivergenceSignal|divergence"
    - from: "src/hydra/model/baseline.py"
      to: "lightgbm"
      via: "LGBMClassifier with conservative defaults"
      pattern: "LGBMClassifier|lgb"
---

<objective>
Build the feature matrix assembler and LightGBM baseline model wrapper. The feature assembler pulls all signal components into a training-ready matrix using point-in-time correct queries. The baseline model wraps LightGBM with conservative defaults and binary classification.

Purpose: This is the predictive engine. It takes divergence signals, options math features, and COT features and predicts whether price will go up or down over a configurable horizon. NO hyperparameter tuning -- conservative defaults only (tuning belongs in Phase 3).

Output: `src/hydra/model/features.py` and `src/hydra/model/baseline.py`, tested.
</objective>

<execution_context>
@/Users/tristanfarmer/.claude/get-shit-done/workflows/execute-plan.md
@/Users/tristanfarmer/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-signal-layer-baseline-model/02-RESEARCH.md
@.planning/phases/02-signal-layer-baseline-model/02-01-SUMMARY.md
@.planning/phases/02-signal-layer-baseline-model/02-03-SUMMARY.md
@src/hydra/data/store/feature_store.py
@src/hydra/signals/options_math/moments.py
@src/hydra/signals/divergence/detector.py
@src/hydra/signals/sentiment/cot_scoring.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement feature matrix assembler with tests</name>
  <files>src/hydra/model/__init__.py, src/hydra/model/features.py, tests/test_model_features.py</files>
  <action>
Create `src/hydra/model/__init__.py` (empty initially).

Create `src/hydra/model/features.py` with `FeatureAssembler` class:

```python
class FeatureAssembler:
    """Assembles feature matrix from feature store + computed signals.

    Feature groups:
    1. COT features: cot_managed_money_net, cot_producer_net, cot_swap_net, cot_total_oi
    2. Implied moments: implied_mean, implied_variance, implied_skew, implied_kurtosis, atm_iv
    3. Greeks flows: gex, vanna_flow, charm_flow
    4. Divergence components: divergence_direction, divergence_magnitude, divergence_confidence
    5. Sentiment: sentiment_score, sentiment_confidence

    NaN values are preserved for LightGBM's native NaN handling.
    """

    FEATURE_NAMES = [
        "cot_managed_money_net", "cot_producer_net", "cot_swap_net", "cot_total_oi",
        "implied_mean", "implied_variance", "implied_skew", "implied_kurtosis", "atm_iv",
        "gex", "vanna_flow", "charm_flow",
        "divergence_direction", "divergence_magnitude", "divergence_confidence",
        "sentiment_score", "sentiment_confidence",
    ]

    def __init__(self, feature_store: FeatureStore):
        self.feature_store = feature_store

    def assemble_at(self, market: str, query_time: datetime) -> dict[str, float | None]:
        """Get feature vector at a specific point in time.
        Returns dict of feature_name -> value (None if unavailable).
        Uses feature_store.get_features_at for point-in-time correctness.
        """

    def assemble_matrix(self, market: str, timestamps: list[datetime]) -> tuple[np.ndarray, list[str]]:
        """Build feature matrix (N x F) for a list of timestamps.
        Returns (matrix, feature_names). NaN for missing values.
        Uses pandas DataFrame internally for alignment.
        """

    def compute_binary_target(self, prices: np.ndarray, horizon: int = 5) -> np.ndarray:
        """Compute binary target: 1 if price[t+horizon] > price[t], else 0.
        Returns array of length len(prices) - horizon.
        Last `horizon` values are NaN (no future data).
        """
```

Create `tests/test_model_features.py` with tests:
1. **test_assemble_at_returns_all_features**: Mock feature store, verify all FEATURE_NAMES present
2. **test_missing_features_are_none**: Feature store missing some features -> None in output
3. **test_assemble_matrix_shape**: N timestamps -> (N, len(FEATURE_NAMES)) matrix
4. **test_binary_target_up**: Price increases -> target = 1
5. **test_binary_target_down**: Price decreases -> target = 0
6. **test_binary_target_horizon**: Last `horizon` entries are NaN

Run tests. All must pass.
  </action>
  <verify>`cd /Users/tristanfarmer/Documents/HYDRA && python -m pytest tests/test_model_features.py -v` -- all tests pass</verify>
  <done>FeatureAssembler correctly pulls features from feature store with point-in-time correctness. Binary target computation works. All tests pass.</done>
</task>

<task type="auto">
  <name>Task 2: Implement LightGBM baseline model wrapper with tests</name>
  <files>src/hydra/model/baseline.py, tests/test_baseline_model.py, src/hydra/model/__init__.py</files>
  <action>
Create `src/hydra/model/baseline.py` with `BaselineModel` class following research code example exactly:

```python
import lightgbm as lgb
import numpy as np

class BaselineModel:
    """LightGBM binary classifier for directional prediction.
    Conservative defaults -- NO hyperparameter tuning in Phase 2.
    """

    DEFAULT_PARAMS = {
        "objective": "binary",
        "metric": "binary_logloss",
        "num_leaves": 31,
        "learning_rate": 0.1,
        "n_estimators": 100,
        "min_child_samples": 20,
        "subsample": 0.8,
        "colsample_bytree": 0.8,
        "reg_alpha": 0.1,
        "reg_lambda": 0.1,
        "verbose": -1,
        "random_state": 42,
    }

    def __init__(self, params: dict | None = None):
        merged = {**self.DEFAULT_PARAMS, **(params or {})}
        self.model = lgb.LGBMClassifier(**merged)
        self._is_fitted = False
        self._feature_names: list[str] = []

    def train(self, X: np.ndarray, y: np.ndarray, feature_names: list[str] | None = None) -> None:
        self.model.fit(X, y)
        self._is_fitted = True
        self._feature_names = feature_names or [f"f{i}" for i in range(X.shape[1])]

    def predict_proba(self, X: np.ndarray) -> np.ndarray:
        """Return P(price up) for each row."""
        return self.model.predict_proba(X)[:, 1]

    def predict(self, X: np.ndarray, threshold: float = 0.5) -> np.ndarray:
        """Return binary predictions."""
        return (self.predict_proba(X) >= threshold).astype(int)

    def feature_importance(self) -> dict[str, float]:
        return dict(zip(self._feature_names, self.model.feature_importances_))

    @property
    def is_fitted(self) -> bool:
        return self._is_fitted
```

Create `tests/test_baseline_model.py` with tests:
1. **test_train_and_predict**: Train on synthetic data, predict_proba returns values in [0, 1]
2. **test_predict_binary**: predict() returns 0s and 1s
3. **test_feature_importance**: After training, feature_importance() returns dict with correct keys
4. **test_not_fitted_raises**: predict_proba before train raises NotFittedError
5. **test_handles_nan_features**: Training data with NaN values does not crash (LightGBM handles natively)
6. **test_custom_params_override**: Passing custom params overrides defaults

Use numpy to generate synthetic training data (e.g., random features, binary labels).

Update `src/hydra/model/__init__.py` to re-export: `FeatureAssembler`, `BaselineModel`.

Run tests. All must pass.
  </action>
  <verify>`cd /Users/tristanfarmer/Documents/HYDRA && python -m pytest tests/test_baseline_model.py -v` -- all tests pass</verify>
  <done>BaselineModel wraps LightGBM with conservative defaults. Handles NaN features. Feature importance extractable. All tests pass.</done>
</task>

</tasks>

<verification>
```bash
cd /Users/tristanfarmer/Documents/HYDRA
python -m pytest tests/test_model_features.py tests/test_baseline_model.py -v
python -c "from hydra.model import FeatureAssembler, BaselineModel; print('Import OK')"
```
</verification>

<success_criteria>
- FeatureAssembler.assemble_at returns all 17 features using point-in-time queries
- FeatureAssembler.assemble_matrix returns (N, 17) ndarray with NaN for missing values
- compute_binary_target correctly computes up/down target over configurable horizon
- BaselineModel trains LightGBM with conservative defaults (no tuning)
- BaselineModel handles NaN features without crashing
- Feature importance is extractable for diagnostics
- All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/02-signal-layer-baseline-model/02-04-SUMMARY.md`
</output>
